{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from scipy.stats import entropy, kurtosis\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance\n",
    "import gc\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "import catboost\n",
    "from catboost import Pool\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pd.set_option('display.max_columns', None)\n",
    "from IPython.display import display\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"../data/\"\n",
    "even_file = root+\"event.csv\"\n",
    "test_file = root+\"test.csv\"\n",
    "train_file = root+\"train.csv\"\n",
    "sample_file = root+\"sample.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file,low_memory=False)\n",
    "test_df = pd.read_csv(test_file,low_memory=False)\n",
    "\n",
    "train_num = len(train_df)\n",
    "data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "event = pd.read_csv(even_file)\n",
    "data = pd.merge(data, event, on='event_id', how='left')\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13559712, 32)\n",
      "(13559712, 40)\n",
      "(13559712, 51)\n",
      "(13559712, 60)\n",
      "(13559712, 63)\n",
      "(13559712, 68)\n",
      "(13559712, 72)\n",
      "(13559712, 73)\n",
      "(13559712, 74)\n",
      "(13559712, 78)\n"
     ]
    }
   ],
   "source": [
    "data['angle*xy'] = data['x']*data['thetamc']*0.01 + data['y']*data['phimc']*0.01\n",
    "\n",
    "data['energymc/t'] = data['energymc']/data['t']\n",
    "\n",
    "data['x/t'] = data['x']/data['t']\n",
    "\n",
    "ss = MinMaxScaler()\n",
    "x1 = ss.fit_transform(data['t'].values.reshape([-1,1]))\n",
    "data['energymc/t'] = data['energymc'].values.reshape([-1,1])/x1\n",
    "#距离相关特征\n",
    "data['slope'] = data['y']/data['x']\n",
    "\n",
    "data['x_cmc'] = (data['x']-data['xcmc'])/(data['xcmc']+data['xcmc'].mean())\n",
    "\n",
    "data['y_cmc'] = (data['y']-data['ycmc'])/(data['ycmc']+data['ycmc'].mean())\n",
    "\n",
    "data['og'] = np.sqrt((data['y']-data['ycmc'])**2 + (data['x']-data['xcmc'])**2)\n",
    "\n",
    "data['og_2'] = abs(data['x'] - data['xcmc'])\n",
    "\n",
    "data['og_3'] = abs(data['y'] - data['ycmc'])\n",
    "\n",
    "data['MH'] = np.abs(data['x']-data['xcmc'])+np.abs(data['y']-data['ycmc'])\n",
    "\n",
    "data['Cosine'] = (data['x']*data['xcmc']+data['y']*data['ycmc'])/(np.sqrt(data['x']**2+data['y']**2)*np.sqrt(data['xcmc']**2+data['ycmc']**2))\n",
    "#以上特征几乎没什么用\n",
    "\n",
    "#以event_id聚合的t、q、x、y排序的特征，其中q与t为较强特征\n",
    "temp = data.sort_values(['event_id','t'])\n",
    "for i in [7]:\n",
    "    data['x_sort_std_win'+str(i)] = temp['x'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "    data['x/t_sort_std_win'+str(i)] = temp['x/t'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "    data['y_sort_std_win'+str(i)] = temp['y'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "for i in [1]:\n",
    "    data['diff_x_'+str(i)] = temp[['x','event_id']].groupby('event_id')['x'].diff(periods=i).fillna(0)\n",
    "    data['diff_t_'+str(i)] = temp[['t','event_id']].groupby('event_id')['t'].diff(periods=i).fillna(0)\n",
    "del temp\n",
    "print(data.shape)\n",
    "\n",
    "temp = data.sort_values(['event_id','hit_id'])\n",
    "for i in [1,8,12]:\n",
    "    data['x/t_sort_std_win'+str(i)+'_hit'] = temp['x/t'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "    data['diff_t_hit_'+str(i)] = temp[['t','event_id']].groupby('event_id')['t'].diff(periods=i).fillna(0)\n",
    "data['speed_og_hit'] = temp['og'].diff(1)/(data['diff_t_hit_1']+1)\n",
    "data['speed_x_hit'] = temp['x'].diff(1)/(data['diff_t_hit_1']+1)\n",
    "del temp\n",
    "print(data.shape)\n",
    "\n",
    "temp = data.sort_values(['event_id','q'])\n",
    "for i in [1,35,12]:\n",
    "    data['t_sort_std_win'+str(i)+'_q'] = temp['t'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "    data['diff_t_q_'+str(i)] = temp[['t','event_id']].groupby('event_id')['t'].diff(periods=i).fillna(0)\n",
    "    data['diff_q_q_'+str(i)] = temp[['q','event_id']].groupby('event_id')['q'].diff(periods=i).fillna(0)\n",
    "data['shift_q'] = temp['q']/temp['q'].shift(-1).fillna(method='pad')\n",
    "data['speed_og_hit_q'] = temp['og'].diff(1)/(data['diff_t_q_1']+1)\n",
    "del temp\n",
    "print(data.shape)\n",
    "\n",
    "#x、y唯一值较少，所以按x、t和y、t排序\n",
    "temp = data.sort_values(['event_id','x','t'])\n",
    "for i in [3]:\n",
    "    data['og_win3_sort_std_hit_x'] = temp['og'].rolling(i, min_periods=1,center=True).std()\n",
    "    data['t_win3_sort_std_hit_x'] = temp['t'].rolling(i, min_periods=1,center=True).std()\n",
    "    data['t_win5_sort_std_hit_x'] = temp['t'].rolling(i, min_periods=1,center=True).std()\n",
    "\n",
    "for i in [12,8,2,1]:\n",
    "    data['diff_t_x_'+str(i)] = temp[['t','event_id']].groupby('event_id')['t'].diff(periods=i).fillna(0)\n",
    "data['speed_y_hit_x'] = temp['y'].diff(1)/(data['diff_t_x_1']+1)\n",
    "data['speed_y_hit_x3'] = temp['y'].diff(2)/(data['diff_t_x_2']+1)\n",
    "del temp\n",
    "print(data.shape)\n",
    "\n",
    "temp = data.sort_values(['event_id','y','t'])\n",
    "for i in [3]:\n",
    "    data['og_win3_sort_std_hit_y'] = temp['og'].rolling(i, min_periods=1,center=True).std()\n",
    "    data['t_win3_sort_std_hit_y'] = temp['t'].rolling(i, min_periods=1,center=True).std()\n",
    "    data['t_win7_sort_std_hit_y'] = temp['t'].rolling(i, min_periods=1,center=True).std()\n",
    "print(data.shape)\n",
    "\n",
    "for i in [1,2,12]:\n",
    "    data['diff_t_y_'+str(i)] = temp[['t','event_id']].groupby('event_id')['t'].diff(periods=i).fillna(0)\n",
    "data['speed_x_hit_y'] = temp['x'].diff(1)/(data['diff_t_y_1']+1)\n",
    "data['speed_x_hit_y2'] = temp['x'].diff(2)/(data['diff_t_y_2']+1)\n",
    "del temp\n",
    "print(data.shape)\n",
    "\n",
    "data['speed_xy_speed'] = data['speed_x_hit_y']/(data['speed_y_hit_x']+1)\n",
    "data['speed_xy_speed2'] = data['speed_x_hit_y2']/(data['speed_y_hit_x3']+1)\n",
    "data['speed_xy_diff3'] = data['diff_t_hit_8']/(data['diff_t_x_8']+1)\n",
    "\n",
    "#整体数据的x、y、terror、q的排序特征，terror、q为强特\n",
    "temp = data[['event_id','t','q','x/t','y','x','og']].sort_values(['x','q'])\n",
    "for i in [41]:\n",
    "    data['t_std_win'+str(i)+'_X'] = temp['t'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "del temp\n",
    "print(data.shape)\n",
    "\n",
    "temp = data[['event_id','t','q','x/t','y','x','og']].sort_values(['y','q'])\n",
    "for i in [41]:\n",
    "    data['t_std_win'+str(i)+'_Y'] = temp['t'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "del temp\n",
    "print(data.shape)\n",
    "\n",
    "temp = data[['event_id','t','q','x/t','y','x','og','terror']].sort_values(['terror','q'])\n",
    "for i in [41]:\n",
    "    data['t_std_win'+str(i)+'_TQ'] = temp['t'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "del temp\n",
    "print(data.shape)\n",
    "\n",
    "temp = data[['event_id','t','q','x/t','y','x','og']].sort_values(['q'])\n",
    "for i in [7,51]:\n",
    "    data['q_std_win'+str(i)+'_Q'] = temp['q'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "    data['t_std_win'+str(i)+'_Q'] = temp['t'].rolling(i, min_periods=1,center=True).std().fillna(0)\n",
    "del temp\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[:train_num]\n",
    "test_df = data[train_num:]\n",
    "del data\n",
    "\n",
    "#为防止过拟合，不使用event文件中所有特征\n",
    "feature= [x for x in train_df.columns if x not in ['nhit','nhitreal', 'energymc', 'thetamc', 'phimc',\n",
    "                                                   'xcmc', 'ycmc','z','flag','index','index_x','index_y','hit_id','event_id']]\n",
    "labels = train_df['flag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练Xgboost模型\n",
    "n_splits = 6\n",
    "kf = KFold(n_splits=n_splits,shuffle=True,random_state=4399)\n",
    "y_pp_xgb = np.zeros(len(test_df))\n",
    "y_pp_xgb_stacking = np.zeros(len(labels))\n",
    "for num,(train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    print ( \">>>\", train_df[feature].shape )\n",
    "    clf = xgb.XGBClassifier(tree_method='gpu_hist',max_depth=7,learning_rate=0.1,\n",
    "          eval_metric='auc',n_estimators=2000,min_child_weight=5,max_bin=1024)\n",
    "    clf.fit(\n",
    "        train_df[feature].iloc[train_index], labels[train_index],\n",
    "        eval_set=[(train_df[feature].iloc[train_index], labels[train_index]),\n",
    "                  (train_df[feature].iloc[test_index], labels[test_index])],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=10,\n",
    "    )\n",
    "\n",
    "    y_pred = clf.predict(train_df[feature].iloc[test_index]) \n",
    "    y_predprob = clf.predict_proba(train_df[feature].iloc[test_index])[:, 1] \n",
    "    \n",
    "    y_pp_xgb_stacking[test_index] = y_predprob\n",
    "      \n",
    "    auc = metrics.roc_auc_score(labels[test_index], y_predprob)\n",
    "    acc = metrics.accuracy_score(labels[test_index],y_pred)\n",
    "\n",
    "    print(\"AUC Score (Train): %f\" % auc) \n",
    "    print(\"ACC Score (Train): %f\" % acc) \n",
    "\n",
    "    y_pp_xgb += clf.predict_proba(test_df[feature])[:, 1] / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练Catboost模型\n",
    "n_splits = 6\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "y_pp_cat_stacking = np.zeros(len(labels))\n",
    "y_pp_cat = np.zeros(len(test_df))\n",
    "for train_index, test_index in kf.split(train_df):\n",
    "    print ( \">>>\", train_df.shape )\n",
    "    model = catboost.CatBoostClassifier(\n",
    "                               iterations=3000,\n",
    "                               depth = 8,\n",
    "                               learning_rate = 0.1,\n",
    "                               custom_loss='AUC',\n",
    "                               eval_metric='AUC',\n",
    "                               task_type = \"GPU\",\n",
    "                              )\n",
    "    train_pool = Pool(train_df[feature].iloc[train_index], labels[train_index], cat_features=cal_cols)\n",
    "    eval_pool = Pool(train_df[feature].iloc[test_index], labels[test_index], cat_features=cal_cols)\n",
    "    \n",
    "    model.fit(train_pool, eval_set=(eval_pool),use_best_model=True,early_stopping_rounds=50,verbose=10)\n",
    "    \n",
    "    y_pred = clf.predict(train_df[feature].iloc[test_index]) \n",
    "    y_predprob = clf.predict_proba(train_df[feature].iloc[test_index])[:, 1] \n",
    "    \n",
    "    y_pp_cat_stacking[test_index] = y_predprob\n",
    "      \n",
    "    auc = metrics.roc_auc_score(labels[test_index], y_predprob)\n",
    "    acc = metrics.accuracy_score(labels[test_index], y_predprob)\n",
    "\n",
    "    print(\"AUC Score (Train): %f\" % auc) \n",
    "    print(\"ACC Score (Train): %f\" % acc) \n",
    "\n",
    "    y_pp_cat += clf.predict_proba(test_df[feature])[:, 1] / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存XGB预测概率用于融合\n",
    "tt = pd.read_csv('../data/test.csv')\n",
    "sub = pd.DataFrame()\n",
    "tt['flag_pre'] =y_pp_xgb\n",
    "tt.loc[tt['t']>1850,'flag_pre']=1\n",
    "tt.loc[tt['t']<-900,'flag_pre']=0\n",
    "tt.loc[tt['q']<0,'flag_pre']=1\n",
    "sub['hit_id']=tt['hit_id']\n",
    "sub['flag_pred'] = tt['flag_pre']\n",
    "sub['event_id'] = tt['event_id']\n",
    "sub.to_csv('../result/xgb_prob.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存CAT预测概率用于融合\n",
    "sub = pd.DataFrame()\n",
    "tt['flag_pre'] =y_pp_cat\n",
    "tt.loc[tt['t']>1850,'flag_pre']=1\n",
    "tt.loc[tt['t']<-900,'flag_pre']=0\n",
    "tt.loc[tt['q']<0,'flag_pre']=1\n",
    "sub['hit_id']=tt['hit_id']\n",
    "sub['flag_pred'] = tt['flag_pre']\n",
    "sub['event_id'] = tt['event_id']\n",
    "sub.to_csv('../result/cat_prob.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
